{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Librerias necesarias, en esta version, 1.6, no existe el SparkSession\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import HiveContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Instalamos pandas para poder escribir spark dfs a .csv\n",
    "!sudo pip install pandas==0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Inicializar el SparkContext\n",
    "sc = SparkContext.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Inicializar el Hive Context\n",
    "sqlContext = HiveContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>Creacion de DF por cada tabla en Hive</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vuelos = sqlContext.sql(\"SELECT * FROM ejercicio1.vuelos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "retrasos = sqlContext.sql(\"SELECT * FROM ejercicio1.retrasos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fecha = sqlContext.sql(\"SELECT * FROM ejercicio1.fecha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "paises = sqlContext.sql(\"SELECT * FROM ejercicio1.paises\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>3.Crear una nueva tabla en Hive, que contenga la siguiente información: Vuelo, Origen, Destino, Retraso.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-------+-------+\n",
      "|Vuelo|Origen|Destino|Retraso|\n",
      "+-----+------+-------+-------+\n",
      "| 6005|   MEX|    ESP|     52|\n",
      "| 2021|   COL|    MEX|     27|\n",
      "| 5528|   ARG|    COL|     36|\n",
      "| 7965|   BRA|    ARG|     82|\n",
      "| 8717|   USA|    BRA|     29|\n",
      "+-----+------+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Inner join de tablas Vuelos y Retrasos\n",
    "HD_ResumenVuelos = sqlContext.sql(\"SELECT v.Vuelo, v.Origen, v.Destino, r.Retraso FROM ejercicio1.vuelos v INNER JOIN ejercicio1.retrasos r ON (v.vuelo=r.vuelo)\")\n",
    "HD_ResumenVuelos.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Crear tabla HD_ResumenVuelos en la ruta hdfs del ejercicio\n",
    "HD_ResumenVuelos.write.option(\"path\", \"hdfs:/home/training/Desktop/Fuentes/HD_ResumenVuelos\").saveAsTable(\"ejercicio1.HD_ResumenVuelos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>(A) ¿De qué país salieron más aviones?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(A) SQL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|          Pais|Salidas|\n",
      "+--------------+-------+\n",
      "|        España|      8|\n",
      "|       Francia|      7|\n",
      "|Estados Unidos|      6|\n",
      "+--------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Left join de Vuelos con Paises, con key orign y cod_pais, agrupado por pais y ordenado desc.\n",
    "HD_ResumenVuelosSalidasSQL = sqlContext.sql(\"SELECT p.Pais, COUNT(v.vuelo) As Salidas FROM ejercicio1.vuelos v LEFT JOIN ejercicio1.paises p ON (v.origen=p.cod_pais) GROUP BY p.Pais ORDER BY Salidas DESC\")\n",
    "HD_ResumenVuelosSalidasSQL.show(3)\n",
    "#De España(8) salieron mas vuelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(A) PySpark</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-----+\n",
      "|          Pais|Vuelo|\n",
      "+--------------+-----+\n",
      "|        Mexico| 6005|\n",
      "|      Colombia| 2021|\n",
      "|     Argentina| 5528|\n",
      "|        Brasil| 7965|\n",
      "|Estados Unidos| 8717|\n",
      "+--------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Crear DF HD_ResumenVuelosSalidas\n",
    "HD_ResumenVuelosSalidas = vuelos.alias(\"v\").join(paises.alias(\"p\"), vuelos.origen == paises.cod_pais)\n",
    "HD_ResumenVuelosSalidas = HD_ResumenVuelosSalidas.select(\"p.Pais\", \"v.Vuelo\")\n",
    "HD_ResumenVuelosSalidas.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+\n",
      "|          Pais|Salidas|\n",
      "+--------------+-------+\n",
      "|        España|      8|\n",
      "|       Francia|      7|\n",
      "|Estados Unidos|      6|\n",
      "+--------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Left join de Vuelos con Paises, con key orign y cod_pais, agrupado por pais y ordenado desc.\n",
    "groupVuelos = HD_ResumenVuelosSalidas.groupBy(\"Pais\")\n",
    "groupVuelos = groupVuelos.agg({'Vuelo':'count'})\n",
    "groupVuelos = groupVuelos.withColumnRenamed(\"count(Vuelo)\", \"Salidas\")\n",
    "groupVuelos = groupVuelos.orderBy(\"Salidas\", ascending=False)\n",
    "groupVuelos.show(3)\n",
    "#De España(8) salieron mas vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Crear tabla HM_ResumenDias en la ruta hdfs del ejercicio\n",
    "groupVuelos.write.option(\"path\", \"hdfs:/home/training/Desktop/Fuentes/HD_ResumenVuelosSalidas\").saveAsTable(\"ejercicio1.HD_ResumenVuelosSalidas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>(B)¿A qué país llegaron más aviones?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(B) SQL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  Pais|Llegadas|\n",
      "+------+--------+\n",
      "|Mexico|       7|\n",
      "| Rusia|       6|\n",
      "|  Peru|       6|\n",
      "+------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Left join de Vuelos con Paises, con key destino y cod_pais, agrupado por pais y ordenado desc.\n",
    "HD_ResumenVuelosLlegadasSQL = sqlContext.sql(\"SELECT p.Pais, COUNT(v.vuelo) As Llegadas FROM ejercicio1.vuelos v LEFT JOIN ejercicio1.paises p ON (v.destino=p.cod_pais) GROUP BY p.Pais ORDER BY Llegadas DESC\")\n",
    "HD_ResumenVuelosLlegadasSQL.show(3)\n",
    "#A Mexico(7) llegaron mas vuelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(B) PySpark</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|     Pais|Vuelo|\n",
      "+---------+-----+\n",
      "|   España| 6005|\n",
      "|   Mexico| 2021|\n",
      "| Colombia| 5528|\n",
      "|Argentina| 7965|\n",
      "|   Brasil| 8717|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Crear DF HD_ResumenVuelosLlegadas\n",
    "HD_ResumenVuelosLlegadas = vuelos.alias(\"v\").join(paises.alias(\"p\"), vuelos.destino == paises.cod_pais)\n",
    "HD_ResumenVuelosLlegadas = HD_ResumenVuelosLlegadas.select(\"p.Pais\", \"v.Vuelo\")\n",
    "HD_ResumenVuelosLlegadas.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------+\n",
      "|  Pais|Llegadas|\n",
      "+------+--------+\n",
      "|Mexico|       7|\n",
      "| Rusia|       6|\n",
      "|  Peru|       6|\n",
      "+------+--------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Join de tablas Vuelos con Retrasos, grop by Destino, con key vuelo y ordenado ascendentemente\n",
    "groupVuelos = HD_ResumenVuelosLlegadas.groupBy(\"Pais\")\n",
    "groupVuelos = groupVuelos.agg({'Vuelo':'count'})\n",
    "groupVuelos = groupVuelos.withColumnRenamed(\"count(Vuelo)\", \"Llegadas\")\n",
    "groupVuelos = groupVuelos.orderBy(\"Llegadas\", ascending=False)\n",
    "groupVuelos.show(3)\n",
    "#A Mexico(7) llegaron mas vuelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Crear tabla HD_ResumenVuelosLlegadas en la ruta hdfs del ejercicio\n",
    "groupVuelos.write.option(\"path\", \"hdfs:/home/training/Desktop/Fuentes/HD_ResumenVuelosLlegadas\").saveAsTable(\"ejercicio1.HD_ResumenVuelosLlegadas\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>(C)¿Qué día hubo más vuelos? ¿Y menos?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(C) SQL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|Dia|Vuelos|\n",
      "+---+------+\n",
      "|  1|     7|\n",
      "|  9|     7|\n",
      "| 20|     7|\n",
      "|  5|     6|\n",
      "| 18|     6|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select de tabla Fecha, agroupado por dia, contando los vuelos \n",
    "HD_ResumenDiasSQL = sqlContext.sql(\"SELECT Dia, Count(Vuelo) as Vuelos FROM ejercicio1.fecha GROUP BY Dia ORDER BY Vuelos DESC\")\n",
    "HD_ResumenDiasSQL.show(5)\n",
    "#Dias 1, 9 y 20 tuvieron mas vuelos (7)\n",
    "\n",
    "HD_ResumenDiasSQLMenor = sqlContext.sql(\"SELECT Dia, Count(Vuelo) as Vuelos FROM ejercicio1.fecha GROUP BY Dia ORDER BY Vuelos ASC\")\n",
    "#HD_ResumenDiasSQLMenor.show(5)\n",
    "#Dias 23, 11, 17, 21 y 8 tuvieron menos vuelos (1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(C) PySpark</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------+\n",
      "|Dia|Vuelos|\n",
      "+---+------+\n",
      "|  1|     7|\n",
      "|  9|     7|\n",
      "| 20|     7|\n",
      "|  5|     6|\n",
      "| 18|     6|\n",
      "+---+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Select de tabla Fecha, agroupado por dia, contando los vuelos \n",
    "HD_ResumenDias = fecha.groupBy(\"Dia\")\n",
    "HD_ResumenDias = HD_ResumenDias.agg({'Vuelo':'count'})\n",
    "HD_ResumenDias = HD_ResumenDias.withColumnRenamed(\"count(Vuelo)\", \"Vuelos\")\n",
    "HD_ResumenDias = HD_ResumenDias.orderBy(\"Vuelos\", ascending=False)\n",
    "HD_ResumenDias.show(5)\n",
    "#Dias 1, 9 y 20 tuvieron mas vuelos (7)\n",
    "\n",
    "HD_ResumenDiasMenor = HD_ResumenDias.orderBy(\"Vuelos\", ascending=True)\n",
    "#HD_ResumenDiasMenor.show(5)\n",
    "#Dias 23, 11, 17, 21 y 8 tuvieron menos vuelos (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Crear tabla HD_ResumenDias en la ruta hdfs del ejercicio\n",
    "HD_ResumenDias.write.option(\"path\", \"hdfs:/home/training/Desktop/Fuentes/HD_ResumenDias\").saveAsTable(\"ejercicio1.HD_ResumenDias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>(D)¿Qué día hubo más retrasos? ¿Y menos?</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(D) SQL</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Join de tabla Fecha on Retrasos con key vuelo, agrupar por dia y ordenar de forma asc/desc\n",
    "HD_ResumenRetrasosSQL = sqlContext.sql(\"SELECT f.Dia, Count(r.retraso) As Retrasos FROM ejercicio1.fecha f INNER JOIN ejercicio1.retrasos r ON (f.vuelo=r.vuelo) GROUP BY f.dia ORDER BY Retrasos DESC\")\n",
    "#El dia 20 de Febrero tuvo mas retrasos\n",
    "\n",
    "HD_ResumenRetrasosMenorSQL = sqlContext.sql(\"SELECT f.Dia, Count(r.retraso) As Retrasos FROM ejercicio1.fecha f INNER JOIN ejercicio1.retrasos r ON (f.vuelo=r.vuelo) GROUP BY f.dia ORDER BY Retrasos ASC\")\n",
    "#Los dias 23, 21, 17 y 11 de Febrero tuvo menos retrasos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|Dia|Retrasos|\n",
      "+---+--------+\n",
      "| 20|       8|\n",
      "|  1|       7|\n",
      "|  9|       7|\n",
      "|  5|       6|\n",
      "| 18|       6|\n",
      "+---+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HD_ResumenRetrasosSQL.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color: Green'>(D) PySpark</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "|Dia|Retraso|\n",
      "+---+-------+\n",
      "|  2|     52|\n",
      "| 25|     27|\n",
      "| 18|     36|\n",
      "+---+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Crear tabla HD_ResumenRetrasos que contenga los min de retraso por dia \n",
    "HD_ResumenRetrasos = fecha.alias(\"f\").join(retrasos.alias(\"r\"), fecha.vuelo == retrasos.vuelo)\n",
    "HD_ResumenRetrasos = HD_ResumenRetrasos.select(\"f.Dia\",\"r.Retraso\")\n",
    "HD_ResumenRetrasos.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+\n",
      "|Dia|Retrasos|\n",
      "+---+--------+\n",
      "| 20|       8|\n",
      "|  1|       7|\n",
      "|  9|       7|\n",
      "|  5|       6|\n",
      "| 18|       6|\n",
      "+---+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Join de tablas Fecha con Retrasos, group by Dia, con key vuelo y ordenado ascendentemente\n",
    "groupRetrasos = HD_ResumenRetrasos.groupBy(\"Dia\")\n",
    "groupRetrasos = groupRetrasos.agg({'Retraso':'count'})\n",
    "groupRetrasos = groupRetrasos.withColumnRenamed(\"count(Retraso)\", \"Retrasos\")\n",
    "groupRetrasos = groupRetrasos.orderBy(\"Retrasos\", ascending=False)\n",
    "groupRetrasos.show(5)\n",
    "#El dia 20 de Febrero tuvo mas retrasos \n",
    "\n",
    "HD_ResumenRetrasosMenor = groupRetrasos.orderBy(\"Retrasos\", ascending=True)\n",
    "#HD_ResumenRetrasosMenor.show(5)\n",
    "#Los dias 23, 21, 17 y 11 de Febrero tuvieron menos retrasos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Crear tabla HD_ResumenRetrasos en la ruta hdfs del ejercicio\n",
    "groupRetrasos.write.option(\"path\", \"hdfs:/home/training/Desktop/Fuentes/HD_ResumenRetrasos\").saveAsTable(\"ejercicio1.HD_ResumenRetrasos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Guardar tablas generadas en .csv \n",
    "HD_ResumenVuelosSalidasSQL.toPandas().to_csv(\"/home/training/Desktop/EJERCICIO VIAJES/Fuentes Finales/HD_ResumenVuelosSalidas.csv\", encoding='utf-8')\n",
    "HD_ResumenVuelosLlegadasSQL.toPandas().to_csv(\"/home/training/Desktop/EJERCICIO VIAJES/Fuentes Finales/HD_ResumenVuelosLlegadas.csv\", encoding='utf-8')\n",
    "HD_ResumenDiasSQL.toPandas().to_csv(\"/home/training/Desktop/EJERCICIO VIAJES/Fuentes Finales/HD_ResumenDias.csv\", encoding='utf-8')\n",
    "HD_ResumenRetrasosSQL.toPandas().to_csv(\"/home/training/Desktop/EJERCICIO VIAJES/Fuentes Finales/HD_ResumenRetrasos.csv\", encoding='utf-8')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>7.Crear un tabla resultado que tenga la información del origen de los vuelos y su retraso acumulado por día (sin importar el destino).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w0 = Window.partitionBy(\"Origen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-------+-----------------+\n",
      "|Origen|Dia|Retraso|Retraso Acumulado|\n",
      "+------+---+-------+-----------------+\n",
      "|   GER|  3|     66|             66.0|\n",
      "|   GER| 12|     99|            165.0|\n",
      "|   GER| 20|     36|            201.0|\n",
      "|   GER| 22|     65|            266.0|\n",
      "|   GER| 26|     16|            282.0|\n",
      "|   GER| 28|     50|            332.0|\n",
      "|   VEN|  5|     82|             82.0|\n",
      "|   VEN| 20|     38|            120.0|\n",
      "|   SUE|  8|     90|             90.0|\n",
      "|   SUE|  9|     52|            192.0|\n",
      "|   SUE|  9|     50|            192.0|\n",
      "|   FRA|  1|     62|             62.0|\n",
      "|   FRA|  3|     19|             81.0|\n",
      "|   FRA|  5|     71|            152.0|\n",
      "|   FRA|  9|     24|            176.0|\n",
      "|   FRA| 14|     14|            190.0|\n",
      "|   FRA| 15|     98|            288.0|\n",
      "|   FRA| 26|     35|            323.0|\n",
      "|   ARG|  9|     71|             71.0|\n",
      "|   ARG| 17|     80|            151.0|\n",
      "+------+---+-------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "HD_RetrasoAcumulado = fecha.alias(\"f\").join(retrasos.alias(\"r\"), \\\n",
    "                      fecha.vuelo==retrasos.vuelo, how=\"left\") \\\n",
    "                      .join(vuelos.alias(\"v\"), vuelos.vuelo==retrasos.vuelo) \\\n",
    "                      .select(\"v.Origen\", \"f.Dia\",\"r.Retraso\")\n",
    "HD_RetrasoAcumulado = HD_RetrasoAcumulado.withColumn('Retraso Acumulado', F.sum('Retraso') \\\n",
    "                      .over(w0.orderBy(F.col('Dia'))))\n",
    "HD_RetrasoAcumulado.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>8.Convertir las operaciones realizadas para resolver el ejercicio 7 en un método definido por el alumno, que devuelva dicho resultado.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class OperacionSQL:\n",
    "    def __init__ (self, *args):\n",
    "        self.dfs = list(args)\n",
    "        \n",
    "    def joinSQL(self, struc):\n",
    "        return self.dfs[0].alias(\"a\") \\\n",
    "               .join(self.dfs[1].alias(\"b\") \\\n",
    "               ,struc.id1==struc.id2,how=struc.tipo)\n",
    "        \n",
    "    def groupBySQL(self, struc, colAlias):\n",
    "        return self.dfs[0].groupBy(struc.col).agg({struc.aggCol:struc.aggOpe}) \\\n",
    "               .withColumnRenamed(\"{}({})\" \\\n",
    "               .format(struc.aggOpe, struc.aggCol), colAlias)\n",
    "        \n",
    "    def orderBySQL(self, col, sort):\n",
    "        order = sort\n",
    "        sort = False if order == \"desc\" else True\n",
    "        return self.dfs[0].orderBy(col, ascending=sort)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class GroupByStructure:\n",
    "    def __init__ (self, col, aggCol, aggOpe):\n",
    "        self.col = col\n",
    "        self.aggCol = aggCol\n",
    "        self.aggOpe = aggOpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class JoinStructure:\n",
    "    def __init__ (self, tipo, id1, id2):\n",
    "        self.tipo = tipo.lower()\n",
    "        self.id1 = id1\n",
    "        self.id2 = id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class WindowFunction: \n",
    "    def __init__ (self, part, newCol, aggCol):\n",
    "        self.part = part\n",
    "        self.newCol = newCol\n",
    "        self.aggCol = aggCol\n",
    "    def windowSum(self, df, sortCol):\n",
    "        w0 = Window.partitionBy(self.part)\n",
    "        return df.withColumn(self.newCol, F.sum(self.aggCol) \\\n",
    "               .over(w0.orderBy(F.col(sortCol))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+-------+-----------------+\n",
      "|Origen|Dia|Retraso|Retraso Acumulado|\n",
      "+------+---+-------+-----------------+\n",
      "|   GER|  3|     66|             66.0|\n",
      "|   GER| 12|     99|            165.0|\n",
      "|   GER| 20|     36|            201.0|\n",
      "|   GER| 22|     65|            266.0|\n",
      "|   GER| 26|     16|            282.0|\n",
      "+------+---+-------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ope1 = OperacionSQL(fecha, retrasos)\n",
    "strc1 = JoinStructure(\"left\", fecha.vuelo, retrasos.vuelo)\n",
    "join1 = ope1.joinSQL(strc1).select(\"a.Dia\", \"b.Retraso\", \"a.vuelo\")\n",
    "\n",
    "ope2 = OperacionSQL(vuelos, join1)\n",
    "strc2 = JoinStructure(\"left\", vuelos.vuelo, join1.vuelo)\n",
    "join2 = ope2.joinSQL(strc2).select(\"a.Origen\", \"b.Dia\", \"b.Retraso\")\n",
    "\n",
    "newWindow1 = WindowFunction (\"Origen\", \"Retraso Acumulado\", \"Retraso\")\n",
    "newWindow1.windowSum(join2, \"Dia\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>9. Sobre el resultado del ejercicio 4, añade otra columna que sea \"Pais_VIP\" donde se identifique si un pais es VIP (los paises VIP son España, Perú y México tanto en origen como destino), para ello haz uso de UDF.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>10. Si se desea almacenar la información del resultado del ejercicio 4 en solo 1 archivo, ¿como lo harías? ¿y si lo quisiera en 10?.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>11. Explica si usarías en algún momento la función cache. Diferencias entre cache y persist.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>12. Sobre el resultado del ejercicio 9, salva en una tabla hive solo cuando el origen sea Perú. Despues de eso vuelve a salvar sobre la misma tabla el resutado de filtrar cuando el origen es México. Por lo tanto en la tabla Hive resultado de este ejercicio deben aparecer los registros de paises Perú y Mexico.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>13. Explica que es el shuffle y como afecta al procesamiento.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style='color:Blue'>14. ¿Cómo identificar el shuffle en un dataframe y cómo corregirlo?</span>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
